{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CjX9HshUJNs_"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll5plTU7JNtD"
      },
      "source": [
        "# **Task1-a**\n",
        "*  In this step, we read the Text-date.txt file line by line. In each line, we changed the uppercase letters to lowercase letters, removed the punctuation marks, and split it into words. Thus, we made it ready for MapReduce."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DH6G5AsZJNtF"
      },
      "outputs": [],
      "source": [
        "def text_clean_and_tokenizate(text):\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r\"\\b[0-9]+\\b\\s*\", \" \", text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text.split(' ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task1-b**\n",
        "*  In this stage, each paragraph was cleaned and separated into words. For each word, a pair of the form (word, 1) was generated."
      ],
      "metadata": {
        "id": "oQDf6xE5JnCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y0E7NgaQJNtH"
      },
      "outputs": [],
      "source": [
        "def map_phase(paragraphs):\n",
        "    mapped = []\n",
        "    for paragraph in paragraphs:\n",
        "        tokens = text_clean_and_tokenizate(paragraph)\n",
        "        for token in tokens:\n",
        "            if token:  # skip empty words\n",
        "                mapped.append((token, 1))\n",
        "    return mapped"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task1-c**\n",
        "*  In the shuffle phase, the (word, 1) pairs coming from the map phase were grouped based on words. The 1 values ​​belonging to these words were added to a list to show the number of times each word occurred"
      ],
      "metadata": {
        "id": "PE7vSlgrNX9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def shuffle_phase(mapped_data):\n",
        "    shuffled = defaultdict(list)\n",
        "    for word, count in mapped_data:\n",
        "        shuffled[word].append(count)\n",
        "    return dict(shuffled)"
      ],
      "metadata": {
        "id": "2n0sN-H4KOfM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task1-d**"
      ],
      "metadata": {
        "id": "1zIBeimON8WD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_phase(shuffled_data):\n",
        "\n",
        "    reduced = {word: sum(counts) for word, counts in shuffled_data.items()}\n",
        "\n",
        "    return reduced"
      ],
      "metadata": {
        "id": "Fz_NzW85KZeG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7DEZosf3MPXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tTx5yWcTJNtI",
        "outputId": "dd680906-1a86-41cd-dd73-475e09a7f209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the top 10 final word frequencies\n",
            "is: 144252\n",
            "the: 77872\n",
            "a: 76969\n",
            "of: 70819\n",
            "to: 43002\n",
            "or: 35375\n",
            "in: 31373\n",
            "and: 26973\n",
            "an: 14541\n",
            "that: 13807\n"
          ]
        }
      ],
      "source": [
        "file_path = \"Text-data.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding='utf-8') as file:\n",
        "    paragraphs = file.readlines()\n",
        "\n",
        "mapped_data = map_phase(paragraphs)\n",
        "shuffled_data = shuffle_phase(mapped_data)\n",
        "reduced_data = reduce_phase(shuffled_data)\n",
        "\n",
        "print(\"the top 10 final word frequencies\")\n",
        "\n",
        "# Convert dictionary items to a list of tuples and sort\n",
        "top_10 = sorted(reduced_data.items(), key=lambda item: item[1], reverse=True)[:10]\n",
        "\n",
        "for word, freq in top_10:\n",
        "    print(f\"{word}: {freq}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f3dOC4L8Nekp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task1-e**\n",
        "\n",
        " **Fine granularity in MapReduce refers to dividing a large task into many small subtasks (such as per word, per line, per file block).\n",
        "This is important because:**\n",
        "\n",
        "*  It allows parallelism, making the process faster on distributed systems.\n",
        "\n",
        "*  It increases fault tolerance, because failure of one small task does not affect the whole process.\n",
        "\n",
        "*  It improves load balancing, as work is more evenly distributed among worker nodes."
      ],
      "metadata": {
        "id": "EBtfrrSYOCSB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6E8aroNJNtL"
      },
      "source": [
        "Source\n",
        "*  https://dylancastillo.co/posts/nlp-snippets-clean-and-tokenize-text-with-python.html\n",
        "*  https://alifanibigdata.wordpress.com/map-reduce-using-python/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvqE1qV-JNtL"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}